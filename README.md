## ğŸ› ï¸ Installation & Setup

### Prerequisites
- Python 3.8 or higher
- pip (Python package installer)

### 1. Clone the Repository
```bash
git clone <repository-url>
cd counseling-llm-ESConv
```

### 2. Install Dependencies
```bash
pip install -r requirements.txt
```

### 3. Set Up API Keys
Create a `.env` file in the project root:
```bash
# Create .env file and add your API keys
nano .env

# Add the following to your .env file:
OPENAI_API_KEY=your_openai_api_key_here
GOOGLE_API_KEY=your_google_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here
TOGETHER_API_KEY=your_together_api_key_here
```

### 4. Run the Project
```bash
# Test the setup
cd scripts/llm_tasks
python process_questions.py
```

##  Project Structure

```
counseling-llm/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Original, unprocessed data
â”‚   â”‚   â””â”€â”€ ESConv.json        # Raw ESConv dataset
â”‚   â”œâ”€â”€ processed/             # Processed conversation data
â”‚   â”‚   â”œâ”€â”€ supporter_questions_with_feedback.json  # Questions grouped by conversation
â”‚   â”‚   â””â”€â”€ individual_questions.json              # Flattened individual questions
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ data_processing/       # Scripts for data extraction and processing
â”‚   â”‚   â”œâ”€â”€ extract_questions.py     # Extract questions from ESConv.json
â”‚   â”‚   â””â”€â”€ prepare_llm_data.py      # Prepare data for LLM training
â”‚   â””â”€â”€ llm_tasks/            # Scripts for LLM training and evaluation
â”‚       â”œâ”€â”€ generate_questions.py    # Generate questions using LLM
â”‚       â”œâ”€â”€ evaluate_questions.py    # Evaluate generated questions
â”‚       â””â”€â”€ train_model.py           # Fine-tune LLM (optional)
â”œâ”€â”€ models/                   # Trained/fine-tuned models
â”œâ”€â”€ results/                  # Evaluation results and outputs
â”œâ”€â”€ configs/                  # Configuration files
â”‚   â””â”€â”€ model_config.json
â””â”€â”€ README.md
```

## ğŸ“Š Data Flow

1. **Raw Data** (`ESConv.json`) â†’ **Extract Questions** â†’ **Processed Data**
2. **Processed Data** â†’ **Prepare LLM Data** â†’ **LLM-Ready Format**
3. **LLM-Ready Data** â†’ **Train/Evaluate LLM** â†’ **Results**

## ğŸš€ Quick Start

### 1. Data Processing (Already Done)
```bash
cd scripts/data_processing/
python extract_questions.py  # Creates supporter_questions_with_feedback.json
```

### 2. Prepare Data for LLM
```bash
python prepare_llm_data.py   # Creates training/validation/test splits with prompts
```

### 3. Generate Questions with LLM
```bash
cd ../llm_tasks/
python generate_questions.py  # Use LLM to generate questions
```

### 4. Evaluate Results
```bash
python evaluate_questions.py  # Compare generated vs. actual questions
```

## ğŸ“ Data Format for LLM

Each training example follows this format:
```json
{
  "prompt": "Given the situation and conversation context, what would be an appropriate counseling question to ask?\n\nSituation: [situation]\nContext: [dialogue_history]\n\nQuestion:",
  "completion": "[actual_supporter_question]",
  "situation": "[situation]",
  "context": "[dialogue_history]"
}
```

## ğŸ› ï¸ Key Scripts

- **`extract_questions.py`**: Extract supporter questions from raw data
- **`prepare_llm_data.py`**: Format data for LLM training with proper prompts
- **`generate_questions.py`**: Use LLM to generate counseling questions
- **`evaluate_questions.py`**: Evaluate quality of generated questions
